{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn modules\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradient boosting models\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy modules\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils function\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "_date_cols = ['host_since', 'first_review', 'last_review']\n",
    "df = pd.read_csv('./data/train.csv', low_memory=False, parse_dates=_date_cols)\n",
    "test_df = pd.read_csv('./data/test.csv', low_memory=False, parse_dates=_date_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_LEN = 33538\n",
    "TESTDF_LEN = 17337\n",
    "# combine df and test_df for feature engineering\n",
    "def combine_df(df, test_df):\n",
    "    entire_df = pd.concat([df, test_df], ignore_index=True)\n",
    "    return entire_df\n",
    "\n",
    "def split(entire_df):\n",
    "    df = entire_df.iloc[:DF_LEN].copy()\n",
    "    test_df = entire_df.iloc[DF_LEN:].copy()\n",
    "    test_df.drop('price', axis=1, inplace=True)\n",
    "    return df, test_df\n",
    "\n",
    "entire_df = combine_df(df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "def pre_drop_cols(df):\n",
    "    useless_col = [\n",
    "        'experiences_offered', 'host_acceptance_rate',\n",
    "        'is_business_travel_ready', \"square_feet\", 'country_code'\n",
    "    ]\n",
    "    unique_id = ['id', 'host_id', 'name', 'host_name']\n",
    "    df.drop(useless_col + unique_id, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "entire_df = pre_drop_cols(entire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean extra people columns\n",
    "def clean_extra_people(df):\n",
    "    df['extra_people'] = df['extra_people'].str.lstrip('$').astype(float)\n",
    "    return df\n",
    "\n",
    "entire_df = clean_extra_people(entire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colnames\n",
    "num_cols = [\n",
    "    'calculated_host_listings_count', 'accommodates', 'bathrooms', 'bedrooms',\n",
    "    'beds', 'guests_included', 'minimum_nights', 'number_of_reviews',\n",
    "    'review_scores_rating', 'review_scores_cleanliness',\n",
    "    'review_scores_location', 'extra_people',\n",
    "]\n",
    "\n",
    "cate_cols = [\n",
    "    'host_is_superhost', 'property_type', 'room_type', 'bed_type',\n",
    "    'neighbourhood_group_cleansed', 'transit', \n",
    "]\n",
    "\n",
    "date_cols = ['host_since', 'first_review', 'last_review']\n",
    "label = ['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by column and compute statistics\n",
    "def featengi_bycol(df, colname, feat_lst): \n",
    "    gourp_cols = num_cols + [colname]\n",
    "    \n",
    "    if 'mean' in feat_lst:\n",
    "        temp_mean = df[gourp_cols].groupby([colname]).transform(lambda x: x.mean())\n",
    "        temp_mean = temp_mean.add_prefix(colname[:5]+'_mean_')\n",
    "        df = pd.concat([df, temp_mean], axis=1)\n",
    "        num_cols.extend(temp_mean.columns.values.tolist())\n",
    "    if 'max' in feat_lst:\n",
    "        temp_max = df[gourp_cols].groupby([colname]).transform(lambda x: x.max())\n",
    "        temp_max = temp_max.add_prefix(colname[:5] + '_max_')\n",
    "        df = pd.concat([df, temp_max], axis=1)\n",
    "        num_cols.extend(temp_max.columns.values.tolist())\n",
    "    return df\n",
    "\n",
    "entire_df = featengi_bycol(entire_df, 'neighbourhood_cleansed', ['mean','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculated_features(df):\n",
    "    # number of accommdates per beds\n",
    "    df['accom_per_beds'] = df['accommodates'] / df['beds']\n",
    "    df['accom_per_beds'] = df['accom_per_beds'].apply(lambda x: 4 if x == float('inf') else x)\n",
    "    if 'accom_per_beds' not in num_cols:\n",
    "        num_cols.append('accom_per_beds')\n",
    "        \n",
    "    # number of accommdates per bath\n",
    "    df['accom_per_bath'] = df['accommodates'] / df['bathrooms']\n",
    "    df['accom_per_bath'] = df['accom_per_bath'].apply(lambda x: 4 if x == float('inf') else x)\n",
    "    if 'accom_per_bath' not in num_cols:\n",
    "        num_cols.append('accom_per_bath')\n",
    "    \n",
    "    # clean transit\n",
    "    df['transit'] = df['transit'].str.contains('Subway|Train|train|subway|Buses|buses').astype('str')\n",
    "    \n",
    "    # 1 if ratio <=1 else 0\n",
    "    df['accom_per_beds_ratio'] = df['accom_per_beds'].apply(lambda x: '1' if x <= 1. else '0')\n",
    "    if 'accom_per_beds_ratio' not in cate_cols:\n",
    "        cate_cols.append('accom_per_beds_ratio')\n",
    "        \n",
    "    bath_per_bed = df['bathrooms'] / df['beds']\n",
    "    df['bath_per_bed'] = bath_per_bed.apply(lambda x: '1' if x >= 1. else '0')\n",
    "    if 'bath_per_bed' not in cate_cols:\n",
    "        cate_cols.append('bath_per_bed')\n",
    "    \n",
    "    # extra people\n",
    "    df['extra_ppl'] = df['accommodates'] - df['guests_included']\n",
    "    if 'extra_ppl' not in num_cols:\n",
    "        num_cols.append('extra_ppl')\n",
    "    \n",
    "    # night duration\n",
    "    df['nights_duration'] = df['maximum_nights'] - df['minimum_nights']\n",
    "    if 'nights_duration' not in num_cols:\n",
    "        num_cols.append('nights_duration')\n",
    "    \n",
    "    return df\n",
    "\n",
    "entire_df = calculated_features(entire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill number of review with 0\n",
    "def fill_null(df):\n",
    "    # fill number of review 0\n",
    "    df['number_of_reviews'] = df['number_of_reviews'].fillna(0)\n",
    "    return df\n",
    "entire_df = fill_null(entire_df)\n",
    "\n",
    "# fill with mean grouoby neighbourhood_group_cleansed\n",
    "entire_df[num_cols] = entire_df[num_cols].fillna(\n",
    "    entire_df[num_cols + ['neighbourhood_group_cleansed']].groupby(\n",
    "        ['neighbourhood_group_cleansed'])[num_cols].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na in date cols\n",
    "def fillna_datetime(df):\n",
    "    temp = df.copy()\n",
    "    for col in date_cols:\n",
    "        df[col] = df[col].fillna(min(df[col]))\n",
    "    return temp\n",
    "\n",
    "entire_df = fillna_datetime(entire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split entire df\n",
    "df, test_df = split(entire_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pipeline\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('scaler', MinMaxScaler())])\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='constant', fill_value='_')\n",
    "            ), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "column_transfomer = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cate_cols),\n",
    "    ('date', MinMaxScaler(), date_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = df[num_cols + cate_cols + date_cols]  \n",
    "y = df.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=10)\n",
    "\n",
    "X_train = column_transfomer.fit_transform(X_train)\n",
    "X_test = column_transfomer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33538, 51), (30184, 95))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search cv\n",
    "def random_search_cv(reg, params):\n",
    "    random_reg = RandomizedSearchCV(reg,\n",
    "                              params,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1,\n",
    "                              scoring=\"neg_root_mean_squared_error\",\n",
    "                              cv=5,\n",
    "                              n_iter=10,\n",
    "                              refit=True,\n",
    "                              random_state=42)\n",
    "    return random_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_reg(X_train, y_train, X_test, y_test):\n",
    "    from numpy.random import randint\n",
    "    lgbm = LGBMRegressor(verbose=0, n_estimators=10000, learning_rate=0.01)\n",
    "\n",
    "    params = {\n",
    "        \"num_leaves\": np.arange(10, 50),\n",
    "        'min_child_samples': np.arange(10, 50),\n",
    "        'min_child_weight': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3],\n",
    "        'max_depth': np.arange(3, 10),\n",
    "        'subsample': uniform(loc=0.2, scale=0.8),\n",
    "        'colsample_bytree': uniform(loc=0.4, scale=0.6),\n",
    "        'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50],\n",
    "        'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]\n",
    "    }\n",
    "\n",
    "    random_lgbm = random_search_cv(lgbm, params)\n",
    "    random_lgbm.fit(X_train,\n",
    "                    y_train,\n",
    "                    eval_set=(X_test, y_test),\n",
    "                    eval_metric='rmse',\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=0)\n",
    "\n",
    "    return random_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_test)\n",
    "    print(\"RMSE\")\n",
    "    print(\"Train RMSE: \" + str(rmse(y_train, y_train_pred)))\n",
    "    print(\"Test RMSE: \" + str(rmse(y_test, y_val_pred)))\n",
    "    print(\"Train R2: \" + str(r2_score(y_train, y_train_pred)))\n",
    "    print(\"Test R2: \" + str(r2_score(y_test, y_val_pred)))\n",
    "    print(\"Best Params: \"+ str(model.best_params_))\n",
    "    print(\"Best Score: \" + str(model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "randSearch_lgbm = lgbm_reg(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE\n",
      "Train RMSE: 68.88395264735065\n",
      "Test RMSE: 73.40196036774593\n",
      "Train R2: 0.7369847202229826\n",
      "Test R2: 0.6345304094582379\n",
      "Best Params: {'colsample_bytree': 0.5752867891211308, 'max_depth': 9, 'min_child_samples': 12, 'min_child_weight': 10.0, 'num_leaves': 16, 'reg_alpha': 5, 'reg_lambda': 0, 'subsample': 0.25204127438822366}\n",
      "Best Score: -85.41377298819543\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "eval_model(randSearch_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average prediction \n",
    "make_submission(y_preds_final.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = column_transfomer.transform(test_df[num_cols + cate_cols + date_cols])\n",
    "make_submission(randSearch_lgbm.predict(X_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(y_test_pred):\n",
    "    from datetime import datetime\n",
    "    test_df = pd.read_csv('./data/test.csv', low_memory=False)\n",
    "    sub_df = pd.DataFrame({'Id': test_df['id'], 'Predicted': y_test_pred})\n",
    "    sub_path = './submission/sub_'+str(datetime.now())+'.csv'\n",
    "    sub_df.to_csv(sub_path, index=False)\n",
    "    return sub_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
